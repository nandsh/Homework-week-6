---
title: "HomeWork-Week-6"
author: "Nandini Sharma"
date: "October 22, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
###Problem - 1
####Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines.


- Your function should take the following arguments: **p1** and **n1** (no default) to pose as the estimated proportion and sample size (i.e., based on your sample data); **p2** and **n2** (both defaulting to NULL) that contain a second sample's proportion and sample size data in the event of a two-sample test; **p0** (no default) as the expected value for the population proportion; and **alternative** (default "two.sided") and **conf.level** (default 0.95), to be used in the same way as in the function `t.test()`.
- When conducting a two-sample test, it should be **p1** that is tested as being smaller or larger than **p2** when alternative="less" or alternative="greater", the same as in the use of x and y in the function `t.test()`.
- The function should perform a one-sample Z-test using **p1**, **n1**, and **p0** if either **p2** or **n2** (or both) is NULL.
- The function should contain a check for the rules of thumb we have talked about ($n * p > 5$ and $n * (1-p) >5$) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
- The function should return a list containing the members Z (the test statistic), P (the appropriate p-value), and CI (the two-sided CI with respect to confidence level).

```{r}
Z.prop.test <- function(p1,n1,p0,p2=NULL,n2=NULL,alternative="two.sided",conf.level=0.95){
  singleSample <- NULL 
  alpha <- (1 - conf.level)
  zStat<-NULL
  CI<-NULL
  pVal<-NULL
   #Check for rule of thumb
    if( (n1*(1-p1) <= 5) || (n1*(p1) <=5 )) {
      warning("The parameters n1 and p1 do not clear the rule of thumb\n n*p >5 and n*(1-p) > 5")
    }
  #Check if it is a two sample z test 
  if( !(is.null(p2)) || !(is.null(n2))){ #Check if either of p2 or n2 is non null
    if(  is.null(p2) || is.null(n2) ) { #Check if only one of p2 and n2 is null
      warning("Inappropriate values of either p2 or n2")
      return(NULL)
    }
      #Check for rule of thumb
      if( (n2*(1-p2) <= 5) || (n2*(p2) <=5 )) {
      warning("The parameters n2 and p2 do not clear the rule of thumb\n n*p >5 and n*(1-p) > 5")
    }
    singleSample <- FALSE
    print("This is a two sample Z test")
    pooledPval <- (p1*n1 + p2*n2)/(n1 + n2)
    zStat <- (p1-p2)/sqrt(pooledPval*(1-pooledPval)*(1/n1+1/n2))
    CI <- (p1-p2) + c(-1,1)*qnorm(1-(alpha/2))*sqrt(p1*(1-p1)/n1+p2*(1-p2)/n2)
    
    #Two tailed test
    if(alternative=="two.sided"){
        pVal <- 2*(1-pnorm(zStat))
       
        }
    #Lower tailed test
    if(alternative=="less"){
       pVal <- pnorm(zStat)
    }
    #Upper tailed test
    if(alternative=="greater"){
       pVal <- (1-pnorm(zStat))
    }
      if(pVal>=alpha){
         print("There is insufficient evidence against the null hypothesis that p1 = p2, and therefore you retain H0")
      }else{
         print("There is sufficient evidence against the null hypothesis that p1 = p2, and therefore we reject H0")
       }
    return(list(ZtestStatistic=zStat,ConfidenceInterval=CI,pValue=pVal))
  }
  #It is a single sample Z-test
  else{

    print("This is a single sample Z test")
    singleSample<-TRUE
    zStat <- (p1-p0)/sqrt((p0*(1-p0))/n1)
    #Check the alternative hypothesis
    #Two sided test
    if(alternative=="two.sided"){
    pVal <- 2*(1-pnorm(zStat))
    }
    #Lower tailed test
    if(alternative=="less"){
      pVal <- pnorm(zStat)
    }
    #Upper tailed test
    if(alternative=="greater"){
      pVal <- 1-pnorm(zStat)
    }
    CI <- p1+c(-1,1)*qnorm(1-(alpha/2))*sqrt(p1*(1-p1)/n1)
    if(pVal>=alpha){
         cat("There is insufficient evidence against the null hypothesis that p0 =",p0," and therefore you retain H0 \n" )
      }else{
         print("There is sufficient evidence against the null hypothesis that p0 =",p0," and therefore we reject H0 \n")
       }
    return(list(ZtestStatistic=zStat,ConfidenceInterval=CI,pValue=pVal))
  }
 
}
```
###Problem - 2
####The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity ("MaxLongevity\_m") measured in months from species' brain size ("Brain\_Size\_Species_Mean") measured in grams. Do the following for both **longevity~brain size** and **log(longevity)~log(brain size)**.

```{r}
#Reading Data
library(curl)
f <- curl("https://raw.githubusercontent.com/difiore/ADA2016/master/KamilarAndCooperData.csv")
my_data <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
```

- Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function `geom_text()`).

```{r}
require(ggplot2)
regCoef0<-round(coef(lm(MaxLongevity_m~Brain_Size_Species_Mean,data=my_data))[1],2)
regCoef1<-round(coef(lm(MaxLongevity_m~Brain_Size_Species_Mean,data=my_data))[2],2)

sca_plot_a<-ggplot(my_data, aes(x = Brain_Size_Species_Mean, y =  MaxLongevity_m)) + geom_point() + geom_smooth(method = "lm") + annotate("text", x = 200, y=700, label = paste("longevity=", regCoef0, "+", regCoef1, "* brainSize")) + ggtitle("longevity ~ brain size")
sca_plot_a

logregCoef0<-round(coef(lm(log(MaxLongevity_m)~log(Brain_Size_Species_Mean),data=my_data))[1],2)
logregCoef1<-round(coef(lm(log(MaxLongevity_m)~log(Brain_Size_Species_Mean),data=my_data))[2],2)
sca_plot_b<-ggplot(my_data, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m) )) + geom_point() + geom_smooth(method = "lm") + annotate("text", x = 2, y=6.5, label = paste("longevity=", logregCoef0, "+", logregCoef1, "* brainSize"))+ ggtitle("LOG(longevity) ~ LOG(brain size)")
sca_plot_b

```


- Identify and interpret the point estimate of the slope ($\beta_1$), as well as the outcome of the test associated with the hypotheses H0: $\beta_1$ = 0; HA: $\beta_1$ ≠ 0. 
```{r}
#Point estimate of the regression coefficient beta1
fittedData <- lm(MaxLongevity_m~Brain_Size_Species_Mean,data=my_data)
summary(fittedData)

```
####Interpretations:
####Point esimates of Coefficient ($\beta_1\$): For every one-unit increase in the brain size, MaxLongevity would increase by 1.218 months
####Outcome of Hypotheses H0: beta1 = 0 , HA beta1  ≠ 0 : Since p < 2e-16, it means that it is evident from the tests that the brain size does impact the longevity
```{r}
#Point estimates of the regression coefficient beta1 : Logarithmic values
logfittedData <- lm(log(MaxLongevity_m)~log(Brain_Size_Species_Mean),data=my_data)
summary(fittedData)
```
####LOGS:Interpretation from the point esimates of Coefficient ($\beta_1\$): For every one-unit increase in the log of brain size, log of MaxLongevity would increase by .23415 units
####LOGS:Outcome of Hypotheses H0: beta1 = 0 , HA beta1  ≠ 0 : Since p < 2e-16, it means that it is evident from the tests that the brain size does impact the longevity

Also, find a 90 percent CI for the slope ($\beta_1$) parameter.
```{r}
#Confidence interval beta1 
confint(fittedData,level=0.90)[2,]
#Confidence interval beta1 logarithmic value
confint(logfittedData,level=0.90)[2,]
```


- Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.
```{r}
subframe<-data.frame(cbind(my_data$Brain_Size_Species_Mean,my_data$MaxLongevity_m))
subframe<-na.omit(subframe)
names(subframe)<-c("Brain_Size_Species_Mean","MaxLongevity_m")
subfittedData <- lm(MaxLongevity_m~Brain_Size_Species_Mean,data=subframe)
ci <- predict(subfittedData, newdata = data.frame(Brain_Size_Species_Mean = subframe$Brain_Size_Species_Mean), interval = "confidence", level = 0.90)
subframe <- cbind(subframe,ci)
names(subframe)<-c("Brain_Size_Species_Mean","MaxLongevity_m","cifit","cilwr","ciupr")
pi <- predict(subfittedData, newdata = data.frame(Brain_Size_Species_Mean = subframe$Brain_Size_Species_Mean), interval = "prediction", level = 0.90)
subframe <- cbind(subframe,pi)
head(subframe)
ggplot(data = subframe, aes(x = Brain_Size_Species_Mean , y = MaxLongevity_m) ) + geom_point() + geom_line(aes(x = Brain_Size_Species_Mean, y = cifit, colour = cifit)) + geom_line(aes(x = Brain_Size_Species_Mean, y = cilwr, colour = cilwr)) + geom_line(aes(x = Brain_Size_Species_Mean, y = ciupr,colour = ciupr)) + geom_line(aes(x = Brain_Size_Species_Mean, y = lwr,colour = lwr)) + geom_line(aes(x = Brain_Size_Species_Mean, y = upr,colour = upr)) + guides(colour = "legend")

#For logarithmic values
logsubframe<-data.frame(cbind(log(my_data$Brain_Size_Species_Mean),log(my_data$MaxLongevity_m)))
logsubframe<-na.omit(logsubframe)
names(logsubframe)<-c("logBrain_Size_Species_Mean","logMaxLongevity_m")

logsubfittedData <- lm(logMaxLongevity_m~logBrain_Size_Species_Mean,data=logsubframe)
ci <- predict(logsubfittedData, newdata = data.frame(logBrain_Size_Species_Mean = logsubframe$logBrain_Size_Species_Mean), interval = "confidence", level = 0.90)

logsubframe <- cbind(logsubframe,ci)

names(logsubframe)<-c("logBrain_Size_Species_Mean","logMaxLongevity_m","cifit","cilwr","ciupr")
pi <- predict(logsubfittedData, newdata = data.frame(logBrain_Size_Species_Mean = logsubframe$logBrain_Size_Species_Mean), interval = "prediction", level = 0.90)
logsubframe <- cbind(logsubframe,pi)

head(logsubframe)
ggplot(data = logsubframe, aes(x = logBrain_Size_Species_Mean , y = logMaxLongevity_m) ) + geom_point() + geom_line(aes(x = logBrain_Size_Species_Mean, y = cifit), colour = "black",show.legend = TRUE) + geom_line(aes(x = logBrain_Size_Species_Mean, y = cilwr), colour = "blue",show.legend = TRUE) + geom_line(aes(x = logBrain_Size_Species_Mean, y = ciupr),colour = "blue",show.legend = TRUE) + geom_line(aes(x = logBrain_Size_Species_Mean, y = lwr),colour = "red",show.legend = TRUE) + geom_line(aes(x = logBrain_Size_Species_Mean, y = upr),colour = "red",show.legend = TRUE) + scale_colour_manual("Lines", labels=c("fitted", "conf interval","prediction interval"), values=c("black","red", "blue"))
```

- Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
```{r}
#Point Estimate
longevityPointEst<-as.numeric(regCoef0+regCoef1*800)
longevityPointEst
#Associated 90% PI
longevityPi <- predict(subfittedData,newdata=data.frame(Brain_Size_Species_Mean=800),interval="prediction",level=0.90)
longevityPi

#For Logarithmic values
#Point estimate
loglongevityPointEst<-as.numeric(logregCoef0+logregCoef1*log(800))
loglongevityPointEst
#Associated 90% PI
loglongevityPi <- predict(logsubfittedData,newdata=data.frame(logBrain_Size_Species_Mean=log(800)),interval="prediction",level=0.90)
loglongevityPi
```
- Looking at your two models, which do you think is better? Why?
